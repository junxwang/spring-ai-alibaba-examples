<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯­éŸ³åŠ©æ‰‹</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem;
        }

        h1 {
            font-size: 1.8rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #38ef7d, #11998e);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .subtitle {
            color: #888;
            font-size: 0.9rem;
            margin-bottom: 2rem;
        }

        .container {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 2rem;
            max-width: 400px;
            width: 100%;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .mic-area {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem 0;
        }

        .mic-btn {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #11998e, #38ef7d);
            color: #fff;
            font-size: 2.5rem;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 20px rgba(56, 239, 125, 0.3);
        }

        .mic-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 30px rgba(56, 239, 125, 0.4);
        }

        .mic-btn.recording {
            background: linear-gradient(135deg, #ff416c, #ff4b2b);
            box-shadow: 0 4px 20px rgba(255, 65, 108, 0.5);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {

            0%,
            100% {
                box-shadow: 0 0 0 0 rgba(255, 65, 108, 0.7);
            }

            50% {
                box-shadow: 0 0 0 25px rgba(255, 65, 108, 0);
            }
        }

        .status {
            text-align: center;
            color: #38ef7d;
            margin: 1.5rem 0;
            font-size: 1.1rem;
            min-height: 1.5rem;
        }

        .status.error {
            color: #ff4b2b;
        }

        .transcript {
            background: rgba(0, 0, 0, 0.3);
            padding: 1rem;
            border-radius: 12px;
            margin-top: 1rem;
            min-height: 80px;
        }

        .transcript-label {
            font-size: 0.75rem;
            color: #666;
            margin-bottom: 0.5rem;
        }

        .transcript-text {
            font-size: 0.95rem;
            line-height: 1.5;
            color: #ccc;
        }

        .transcript-text.user {
            color: #38ef7d;
        }

        .transcript-text.agent {
            color: #fff;
        }

        .connection-status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.8rem;
            color: #666;
            margin-bottom: 1rem;
        }

        .connection-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #ff4b2b;
        }

        .connection-dot.connected {
            background: #38ef7d;
        }

        .log-container {
            margin-top: 1.5rem;
        }

        .log-toggle {
            background: none;
            border: none;
            color: #666;
            font-size: 0.75rem;
            cursor: pointer;
            padding: 0.5rem;
        }

        .log {
            background: rgba(0, 0, 0, 0.4);
            padding: 0.8rem;
            border-radius: 8px;
            max-height: 120px;
            overflow-y: auto;
            font-size: 0.7rem;
            color: #666;
            font-family: monospace;
            display: none;
        }

        .log.show {
            display: block;
        }
    </style>
</head>

<body>
    <h1>ğŸ¤ è¯­éŸ³åŠ©æ‰‹</h1>
    <p class="subtitle">æŒ‰ä½è¯´è¯ â†’ AI å›å¤</p>

    <div class="container">
        <div class="connection-status">
            <span class="connection-dot" id="connDot"></span>
            <span id="connText">æœªè¿æ¥</span>
        </div>

        <div class="mic-area">
            <button class="mic-btn" id="micBtn">ğŸ¤</button>
            <p class="status" id="status">ç‚¹å‡»éº¦å…‹é£å¼€å§‹</p>
        </div>

        <div class="transcript">
            <div class="transcript-label">å¯¹è¯</div>
            <div class="transcript-text" id="transcript"></div>
        </div>

        <div class="log-container">
            <button class="log-toggle" onclick="toggleLog()">æ˜¾ç¤ºæ—¥å¿— â–¼</button>
            <div class="log" id="log"></div>
        </div>
    </div>

    <script>
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const logEl = document.getElementById('log');
        const connDot = document.getElementById('connDot');
        const connText = document.getElementById('connText');

        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isRecording = false;
        let isProcessing = false;
        let isPlaying = false;
        let canCancel = false; // Can user cancel processing
        let activeSources = [];
        let processingTimeout = null;
        let cancelCooldown = null;

        // Reset to idle state
        function resetState() {
            // Stop recording resources if active
            if (isRecording) {
                isRecording = false;
                if (processor) {
                    processor.disconnect();
                    processor = null;
                }
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                if (mediaStream) {
                    mediaStream.getTracks().forEach(t => t.stop());
                    mediaStream = null;
                }
            }

            isProcessing = false;
            isPlaying = false;
            canCancel = false;
            if (processingTimeout) {
                clearTimeout(processingTimeout);
                processingTimeout = null;
            }
            if (cancelCooldown) {
                clearTimeout(cancelCooldown);
                cancelCooldown = null;
            }
            // Stop any playing audio
            activeSources.forEach(s => { try { s.stop(); } catch (e) { } });
            activeSources = [];
            nextStartTime = 0;
            lastAudioEndTime = 0;
            // Reset UI
            micBtn.style.opacity = '1';
            micBtn.style.cursor = 'pointer';
            micBtn.classList.remove('recording');
            micBtn.textContent = 'ğŸ¤';
            status.textContent = 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹';
            status.classList.remove('error');
        }

        // è¿æ¥ WebSocket
        function connect() {
            const wsHost = location.port === '8081' ? location.host : 'localhost:8081';
            ws = new WebSocket('ws://' + wsHost + '/ws/voice');
            ws.binaryType = 'arraybuffer';

            ws.onopen = () => {
                log('WebSocket å·²è¿æ¥');
                connDot.classList.add('connected');
                connText.textContent = 'å·²è¿æ¥';
                status.textContent = 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹';
            };

            ws.onclose = () => {
                log('WebSocket æ–­å¼€');
                connDot.classList.remove('connected');
                connText.textContent = 'æœªè¿æ¥';
                setTimeout(connect, 3000);
            };

            ws.onerror = (e) => {
                log('WebSocket é”™è¯¯');
                status.textContent = 'è¿æ¥é”™è¯¯';
                status.classList.add('error');
            };

            ws.onmessage = handleMessage;
        }

        // å¤„ç†æœåŠ¡å™¨æ¶ˆæ¯
        function handleMessage(event) {
            if (event.data instanceof ArrayBuffer) {
                // éŸ³é¢‘æ•°æ®
                log('æ”¶åˆ°éŸ³é¢‘: ' + event.data.byteLength + ' bytes');
                playAudio(event.data);
            } else {
                // JSON äº‹ä»¶
                try {
                    const data = JSON.parse(event.data);
                    handleEvent(data);
                } catch (e) {
                    log('æ¶ˆæ¯: ' + event.data);
                }
            }
        }

        // Handle events
        function handleEvent(event) {
            log('äº‹ä»¶: ' + event.type);

            // Clear timeout on any valid event
            if (processingTimeout) {
                clearTimeout(processingTimeout);
                processingTimeout = null;
            }

            switch (event.type) {
                case 'stt_chunk':
                    status.textContent = 'è¯†åˆ«ä¸­: ' + event.transcript;
                    break;
                case 'stt_output':
                    status.textContent = 'ä½ è¯´: ' + event.transcript;
                    transcript.innerHTML = '<span class="user">ä½ : ' + event.transcript + '</span><br>';
                    break;
                case 'agent_chunk':
                    const agentSpan = document.getElementById('agentResponse') ||
                        (() => {
                            const span = document.createElement('span');
                            span.id = 'agentResponse';
                            span.className = 'agent';
                            transcript.appendChild(document.createTextNode('AI: '));
                            transcript.appendChild(span);
                            return span;
                        })();
                    agentSpan.textContent += event.text;
                    status.textContent = 'AI å›å¤ä¸­...';
                    break;
                case 'agent_end':
                    status.textContent = 'è¯­éŸ³åˆæˆä¸­...';
                    break;
                case 'tts_chunk':
                    break;
                case 'error':
                    status.textContent = 'é”™è¯¯: ' + event.message;
                    status.classList.add('error');
                    resetState();
                    break;
            }
        }

        // ------ éŸ³é¢‘æ’­æ”¾é€»è¾‘ (PCMæµå¼æ’­æ”¾) ------
        let nextStartTime = 0;
        let pcmAudioCtx = null;
        let lastAudioEndTime = 0; // è·Ÿè¸ªæœ€åä¸€æ®µéŸ³é¢‘ç»“æŸæ—¶é—´

        function initAudioContext() {
            if (!pcmAudioCtx) {
                pcmAudioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            }
            if (pcmAudioCtx.state === 'suspended') {
                pcmAudioCtx.resume();
            }
        }

        function playAudio(arrayBuffer) {
            initAudioContext();
            isPlaying = true;
            canCancel = true; // Allow interrupt during playback
            status.textContent = 'AI æ’­æ”¾ä¸­...ï¼ˆç‚¹å‡»æ‰“æ–­ï¼‰';
            micBtn.style.opacity = '0.7';
            micBtn.style.cursor = 'pointer';

            // Convert ArrayBuffer (Int16 PCM) to Float32
            const int16Data = new Int16Array(arrayBuffer);
            const float32Data = new Float32Array(int16Data.length);
            for (let i = 0; i < int16Data.length; i++) {
                float32Data[i] = int16Data[i] / 32768.0;
            }

            // Create AudioBuffer
            const audioBuffer = pcmAudioCtx.createBuffer(1, float32Data.length, 16000);
            audioBuffer.getChannelData(0).set(float32Data);

            // Create source node
            const source = pcmAudioCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(pcmAudioCtx.destination);

            // Calculate start time for seamless playback
            const currentTime = pcmAudioCtx.currentTime;
            if (nextStartTime < currentTime) {
                nextStartTime = currentTime + 0.05;
            }

            source.start(nextStartTime);
            activeSources.push(source);

            nextStartTime += audioBuffer.duration;
            lastAudioEndTime = nextStartTime;

            // When audio ends
            source.onended = () => {
                // Remove from active sources
                const idx = activeSources.indexOf(source);
                if (idx > -1) activeSources.splice(idx, 1);

                // If all audio finished naturally
                if (activeSources.length === 0 && pcmAudioCtx.currentTime >= lastAudioEndTime - 0.1) {
                    isProcessing = false;
                    isPlaying = false;
                    canCancel = false;

                    if (isRecording) {
                        status.textContent = 'è¯´è¯ä¸­...æ¾å¼€ç»“æŸ';
                    } else {
                        status.textContent = 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹';
                    }

                    micBtn.style.opacity = '1';
                    micBtn.style.cursor = 'pointer';
                    // Clean up agentResponse span
                    const agentSpan = document.getElementById('agentResponse');
                    if (agentSpan) {
                        agentSpan.removeAttribute('id');
                    }
                }
            };
        }

        // Toggle recording
        async function toggleRecording() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                status.textContent = 'æœªè¿æ¥ï¼Œè¯·ç¨å€™';
                return;
            }

            // If processing or playing, clicking mic cancels (only if cooldown passed)
            if (isProcessing || isPlaying) {
                if (canCancel) {
                    log('ç”¨æˆ·å–æ¶ˆï¼Œé‡ç½®çŠ¶æ€');
                    resetState();
                } else {
                    log('è¯·ç­‰å¾…å‘é€å®Œæˆ...');
                }
                return;
            }

            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        let bytesSent = 0; // Track sent audio bytes

        // å¼€å§‹å½•éŸ³ï¼ˆæµå¼å‘é€ PCMï¼‰
        async function startRecording() {
            try {
                log('è¯·æ±‚éº¦å…‹é£æƒé™...');
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(mediaStream);

                bytesSent = 0; // Reset counter

                // åˆ›å»º ScriptProcessor å¤„ç†éŸ³é¢‘
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;

                    const input = e.inputBuffer.getChannelData(0);
                    // è½¬æ¢ä¸º 16-bit PCM
                    const pcm = new Int16Array(input.length);
                    for (let i = 0; i < input.length; i++) {
                        pcm[i] = Math.max(-32768, Math.min(32767, input[i] * 32768));
                    }

                    // å‘é€ PCM æ•°æ®
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        ws.send(pcm.buffer);
                        bytesSent += pcm.byteLength;
                    }
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                isRecording = true;
                micBtn.classList.add('recording');
                micBtn.textContent = 'â¹';
                status.textContent = 'è¯´è¯ä¸­...æ¾å¼€ç»“æŸ';
                status.classList.remove('error');
                log('å¼€å§‹å½•éŸ³ (PCM 16kHz 16-bit)');

            } catch (err) {
                log('éº¦å…‹é£é”™è¯¯: ' + err.message);
                status.textContent = 'æ— æ³•è®¿é—®éº¦å…‹é£';
                status.classList.add('error');
            }
        }

        // åœæ­¢å½•éŸ³
        function stopRecording() {
            isRecording = false;

            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(t => t.stop());
                mediaStream = null;
            }

            micBtn.classList.remove('recording');
            micBtn.textContent = 'ğŸ¤';
            log('åœæ­¢å½•éŸ³');

            // Check if we actually sent enough data
            if (bytesSent < 1000) {
                log('å½•éŸ³è¿‡çŸ­æˆ–ä¸ºç©ºï¼Œå–æ¶ˆå¤„ç†');
                status.textContent = 'å½•éŸ³è¿‡çŸ­';
                setTimeout(() => {
                    status.textContent = 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹';
                }, 1500);
                return;
            }

            // Start processing state (no cancel allowed during first 3 seconds)
            isProcessing = true;
            canCancel = false;
            micBtn.style.opacity = '0.5';
            micBtn.style.cursor = 'not-allowed';

            // Send end marker
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'audio_end' }));
            }

            status.textContent = 'å‘é€ä¸­...';

            // Allow cancel after 3 seconds
            cancelCooldown = setTimeout(() => {
                if (isProcessing && !isPlaying) {
                    canCancel = true;
                    micBtn.style.cursor = 'pointer';
                    status.textContent = 'å¤„ç†ä¸­...ï¼ˆç‚¹å‡»å–æ¶ˆï¼‰';
                }
            }, 3000);

            // Set timeout to reset state if no response in 20 seconds
            processingTimeout = setTimeout(() => {
                log('å¤„ç†è¶…æ—¶ï¼Œé‡ç½®çŠ¶æ€');
                status.textContent = 'æœªæ”¶åˆ°å“åº”ï¼Œè¯·é‡è¯•';
                resetState();
            }, 20000);
        }

        // æ—¥å¿—
        function log(msg) {
            const time = new Date().toLocaleTimeString();
            logEl.innerHTML += time + ' ' + msg + '\n';
            logEl.scrollTop = logEl.scrollHeight;
            console.log(msg);
        }

        function toggleLog() {
            logEl.classList.toggle('show');
        }

        // äº‹ä»¶ç»‘å®š
        micBtn.addEventListener('click', toggleRecording);

        // åˆå§‹åŒ–
        connect();
    </script>
</body>

</html>